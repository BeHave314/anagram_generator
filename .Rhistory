# add column for character count
mutate(word = tolower(Name),
num_characters = nchar(word)) %>%
select(word, num_characters)
# word to find
output_word <- "elizabeth"
# starting word
input_word <- "betheliza"
# filer dataset to match number of characters
input_characters <- nchar(input_word)
# filter dataset to same number of characters
df_search<- df_words %>%
filter(num_characters == input_characters)
# turn input string to vector
input_vector <- as.vector(str_split_fixed(input_word, pattern = "",
n = nchar(input_word)))
num_samples = 10000
for(i in 1:num_samples){
df_search[i, 'rand_word'] <- paste(sample(input_vector, size = nchar(input_word), replace = T),
sep = "",
collapse = ""
)
}
# Filter random words to match on in dictionary
df_search_reduced <- df_search %>%
filter(rand_word %in% df_words$word)
# test if word was found
if (output_word %in% df_search_reduced$rand_word) {
print("Your desired word was found")
} else {
print("No words found")
}
View(df_search)
df_search
library(lexicon)
library(dplyr)
library(stringr)
# obtain dataset to work from
df_words <- lexicon::freq_first_names %>%
# add column for character count
mutate(word = tolower(Name),
num_characters = nchar(word)) %>%
select(word, num_characters)
View(df_words)
# word to find
output_word <- "elizabeth"
# starting word
input_word <- "betheliza"
# filer dataset to match number of characters
input_characters <- nchar(input_word)
# filter dataset to same number of characters
df_search<- df_words %>%
filter(num_characters == input_characters)
View(df_search)
# turn input string to vector
input_vector <- as.vector(str_split_fixed(input_word, pattern = "",
n = nchar(input_word)))
num_samples = 10000
for(i in 1:num_samples){
df_search[i, 'rand_word'] <- paste(sample(input_vector, size = nchar(input_word), replace = T),
sep = "",
collapse = ""
)
}
# filter dataset to same number of characters
df_words<- df_words %>%
filter(num_characters == input_characters)
df_words <- lexicon::freq_first_names %>%
# add column for character count
mutate(word = tolower(Name),
num_characters = nchar(word)) %>%
select(word, num_characters)
# word to find
output_word <- "elizabeth"
# starting word
input_word <- "betheliza"
# filer dataset to match number of characters
input_characters <- nchar(input_word)
# filter dataset to same number of characters
df_words<- df_words %>%
filter(num_characters == input_characters)
# turn input string to vector
input_vector <- as.vector(str_split_fixed(input_word, pattern = "",
n = nchar(input_word)))
library(lexicon)
library(dplyr)
library(stringr)
df_words <- lexicon::freq_first_names %>%
# add column for character count
mutate(word = tolower(Name),
num_characters = nchar(word)) %>%
select(word, num_characters)
# word to find
output_word <- "elizabeth"
# starting word
input_word <- "betheliza"
# filer dataset to match number of characters
input_characters <- nchar(input_word)
# filter dataset to same number of characters
df_words<- df_words %>%
filter(num_characters == input_characters)
View(df_words)
# turn input string to vector
input_vector <- as.vector(str_split_fixed(input_word, pattern = "",
n = nchar(input_word)))
num_samples = 10000
for(i in 1:num_samples){
df_search[i, 'rand_word'] <- paste(sample(input_vector, size = nchar(input_word), replace = T),
sep = "",
collapse = ""
)
}
df_search <- data.frame(rand_word = NA)
for(i in 1:num_samples){
df_search[i, 'rand_word'] <- paste(sample(input_vector, size = nchar(input_word), replace = T),
sep = "",
collapse = ""
)
}
View(df_search)
# Filter random words to match on in dictionary
df_search_reduced <- df_search %>%
filter(rand_word %in% df_words$word)
# obtain dataset to work from
df_words <- lexicon::freq_first_names %>%
# add column for character count
mutate(word = tolower(Name),
num_characters = nchar(word)) %>%
select(word, num_characters)
# starting word
input_word <- "riama"
# filer dataset to match number of characters
input_characters <- nchar(input_word)
# filter dataset to same number of characters
df_words<- df_words %>%
filter(num_characters == input_characters)
# turn input string to vector
input_vector <- as.vector(str_split_fixed(input_word, pattern = "",
n = nchar(input_word)))
num_samples = 10000
df_search <- data.frame(rand_word = NA)
for(i in 1:num_samples){
df_search[i, 'rand_word'] <- paste(sample(input_vector, size = nchar(input_word), replace = T),
sep = "",
collapse = ""
)
}
for(i in 1:num_samples){
df_search[i, 'rand_word'] <- paste(sample(input_vector, size = nchar(input_word), replace = FALSE),
sep = "",
collapse = ""
)
}
# Filter random words to match on in dictionary
df_search_reduced <- df_search %>%
filter(rand_word %in% df_words$word)
View(df_search_reduced)
# test if word was found
if (output_word %in% df_search_reduced$rand_word) {
print("Your desired word was found")
} else {
print("No words found")
}
df_search_reduced$rand_word
output_word %in% df_search_reduced$rand_word
output_word
# word to find
output_word <- "maria"
# test if word was found
if (output_word %in% df_search_reduced$rand_word) {
print("Your desired word was found")
} else {
print("No words found")
}
# test if word was found
if (output_word %in% df_search_reduced$rand_word) {
print("Your desired word was found!!!")
} else {
print("No words found")
}
# obtain dataset to work from
df_words <- lexicon::freq_first_names %>%
# add column for character count
mutate(word = tolower(Name),
num_characters = nchar(word)) %>%
select(word, num_characters)
# word to find
output_word <- "sharon"
library(lexicon)
library(dplyr)
library(stringr)
# obtain dataset to work from
df_words <- lexicon::freq_first_names %>%
# add column for character count
mutate(word = tolower(Name),
num_characters = nchar(word)) %>%
select(word, num_characters)
# word to find
output_word <- "sharon"
# starting word
input_word <- "ronsha"
# filer dataset to match number of characters
input_characters <- nchar(input_word)
# filter dataset to same number of characters
df_words<- df_words %>%
filter(num_characters == input_characters)
View(df_words)
# turn input string to vector
input_vector <- as.vector(str_split_fixed(input_word, pattern = "",
n = nchar(input_word)))
num_samples = 10000
df_search <- data.frame(rand_word = NA)
for(i in 1:num_samples){
df_search[i, 'rand_word'] <- paste(sample(input_vector, size = nchar(input_word), replace = FALSE),
sep = "",
collapse = ""
)
}
View(df_search)
# Filter random words to match on in dictionary
df_search_reduced <- df_search %>%
filter(rand_word %in% df_words$word)
View(df_search_reduced)
paste(df_search_reduced$rand_word)
# obtain dataset to work from
df_words <- lexicon::freq_first_names %>%
# add column for character count
mutate(word = tolower(Name),
num_characters = nchar(word)) %>%
select(word, num_characters)
# word to find
output_word <- "deborah"
# starting word
input_word <- "bordeah"
# filer dataset to match number of characters
input_characters <- nchar(input_word)
# filter dataset to same number of characters
df_words<- df_words %>%
filter(num_characters == input_characters)
# turn input string to vector
input_vector <- as.vector(str_split_fixed(input_word, pattern = "",
n = nchar(input_word)))
num_samples = 10000
df_search <- data.frame(rand_word = NA)
for(i in 1:num_samples){
df_search[i, 'rand_word'] <- paste(sample(input_vector, size = nchar(input_word), replace = FALSE),
sep = "",
collapse = ""
)
}
# Filter random words to match on in dictionary
df_search_reduced <- df_search %>%
filter(rand_word %in% df_words$word)
# test if word was found
if (output_word %in% df_search_reduced$rand_word) {
print("Your desired word was found!!!")
} else {
print("No words found")
}
paste(df_search_reduced$rand_word)
# obtain dataset to work from
df_words <- lexicon::freq_first_names %>%
# add column for character count
mutate(word = tolower(Name),
num_characters = nchar(word)) %>%
select(word, num_characters)
# word to find
output_word <- "elizabeth"
# starting word
input_word <- "bethlizae"
# filer dataset to match number of characters
input_characters <- nchar(input_word)
# filter dataset to same number of characters
df_words<- df_words %>%
filter(num_characters == input_characters)
# turn input string to vector
input_vector <- as.vector(str_split_fixed(input_word, pattern = "",
n = nchar(input_word)))
num_samples = 10000
df_search <- data.frame(rand_word = NA)
for(i in 1:num_samples){
df_search[i, 'rand_word'] <- paste(sample(input_vector, size = nchar(input_word), replace = FALSE),
sep = "",
collapse = ""
)
}
# Filter random words to match on in dictionary
df_search_reduced <- df_search %>%
filter(rand_word %in% df_words$word)
# test if word was found
if (output_word %in% df_search_reduced$rand_word) {
print("Your desired word was found!!!")
} else {
print("No words found")
}
paste(df_search_reduced$rand_word)
num_samples = 1000000
df_search <- data.frame(rand_word = NA)
for(i in 1:num_samples){
df_search[i, 'rand_word'] <- paste(sample(input_vector, size = nchar(input_word), replace = FALSE),
sep = "",
collapse = ""
)
}
# Filter random words to match on in dictionary
df_search_reduced <- df_search %>%
filter(rand_word %in% df_words$word)
# test if word was found
if (output_word %in% df_search_reduced$rand_word) {
print("Your desired word was found!!!")
} else {
print("No words found")
}
paste(df_search_reduced$rand_word)
num_samples = 100000
df_search <- data.frame(rand_word = NA)
for(i in 1:num_samples){
df_search[i, 'rand_word'] <- paste(sample(input_vector, size = nchar(input_word), replace = FALSE),
sep = "",
collapse = ""
)
}
num_samples = 10000
df_search <- data.frame(rand_word = NA)
# when num_samples > 100000 this loop is very slow
for(i in 1:num_samples){
df_search[i, 'rand_word'] <- paste(sample(input_vector, size = nchar(input_word), replace = FALSE),
sep = "",
collapse = ""
)
}
# Filter random words to match on in dictionary
df_search_reduced <- df_search %>%
filter(rand_word %in% df_words$word)
# test if word was found
if (output_word %in% df_search_reduced$rand_word) {
print("Your desired word was found!!!")
} else {
print("No words found")
}
# obtain dataset to work from
df_words <- lexicon::freq_first_names %>%
# add column for character count
mutate(word = tolower(Name),
num_characters = nchar(word)) %>%
select(word, num_characters)
# word to find
output_word <- "barbara"
# starting word
input_word <- "bbaara"
# filer dataset to match number of characters
input_characters <- nchar(input_word)
# starting word
input_word <- "bbaarra"
# filer dataset to match number of characters
input_characters <- nchar(input_word)
# filter dataset to same number of characters
df_words<- df_words %>%
filter(num_characters == input_characters)
# turn input string to vector
input_vector <- as.vector(str_split_fixed(input_word, pattern = "",
n = nchar(input_word)))
num_samples = 10000
df_search <- data.frame(rand_word = NA)
# when input_chracters == 9 & num_samples > 100,000 this loop is very slow
# however at input_charcter == 9 % num_samples 10,000 word is not found
# w
for(i in 1:num_samples){
df_search[i, 'rand_word'] <- paste(sample(input_vector, size = nchar(input_word), replace = FALSE),
sep = "",
collapse = ""
)
}
# Filter random words to match on in dictionary
df_search_reduced <- df_search %>%
filter(rand_word %in% df_words$word)
# test if word was found
if (output_word %in% df_search_reduced$rand_word) {
print("Your desired word was found!!!")
} else {
print("No words found")
}
paste(df_search_reduced$rand_word)
paste(unique(df_search_reduced$rand_word))
# obtain dataset to work from
df_words <- lexicon::freq_first_names %>%
# add column for character count
mutate(word = tolower(Name),
num_characters = nchar(word)) %>%
select(word, num_characters)
# word to find
output_word <- "sandra"
# starting word
input_word <- "drasan"
# filer dataset to match number of characters
input_characters <- nchar(input_word)
# filter dataset to same number of characters
df_words<- df_words %>%
filter(num_characters == input_characters)
# turn input string to vector
input_vector <- as.vector(str_split_fixed(input_word, pattern = "",
n = nchar(input_word)))
num_samples = 10000
df_search <- data.frame(rand_word = NA)
# when input_chracters == 9 & num_samples > 100,000 this loop is very slow
# however at input_charcter == 9 % num_samples 10,000 word is not found
# w
for(i in 1:num_samples){
df_search[i, 'rand_word'] <- paste(sample(input_vector, size = nchar(input_word), replace = FALSE),
sep = "",
collapse = ""
)
}
# test if word was found
if (output_word %in% df_search_reduced$rand_word) {
print("Your desired word was found!!!")
} else {
print("No words found")
}
paste(unique(df_search_reduced$rand_word))
# Filter random words to match on in dictionary
df_search_reduced <- df_search %>%
filter(rand_word %in% df_words$word)
# test if word was found
if (output_word %in% df_search_reduced$rand_word) {
print("Your desired word was found!!!")
} else {
print("No words found")
}
paste(unique(df_search_reduced$rand_word))
View(df_search_reduced)
View(df_search_reduced)
# obtain dataset to work from
df_words <- lexicon::freq_first_names %>%
# add column for character count
mutate(word = tolower(Name),
num_characters = nchar(word)) %>%
select(word, num_characters)
# word to find
output_word <- "mary"
# starting word
input_word <- "arym"
# filer dataset to match number of characters
input_characters <- nchar(input_word)
# filter dataset to same number of characters
df_words<- df_words %>%
filter(num_characters == input_characters)
# turn input string to vector
input_vector <- as.vector(str_split_fixed(input_word, pattern = "",
n = nchar(input_word)))
num_samples = 10000
df_search <- data.frame(rand_word = NA)
# when input_chracters == 9 & num_samples > 100,000 this loop is very slow
# however at input_charcter == 9 % num_samples 10,000 word is not found
# w
for(i in 1:num_samples){
df_search[i, 'rand_word'] <- paste(sample(input_vector, size = nchar(input_word), replace = FALSE),
sep = "",
collapse = ""
)
}
# Filter random words to match on in dictionary
df_search_reduced <- df_search %>%
filter(rand_word %in% df_words$word)
# test if word was found
if (output_word %in% df_search_reduced$rand_word) {
print("Your desired word was found!!!")
} else {
print("No words found")
}
# all unique words
paste(unique(df_search_reduced$rand_word))
# obtain dataset to work from
df_words <- lexicon::freq_first_names %>%
# add column for character count
mutate(word = tolower(Name),
num_characters = nchar(word)) %>%
select(word, num_characters)
# word to find
output_word <- "dorothy"
# starting word
input_word <- "thydoro"
# filer dataset to match number of characters
input_characters <- nchar(input_word)
# filter dataset to same number of characters
df_words<- df_words %>%
filter(num_characters == input_characters)
# turn input string to vector
input_vector <- as.vector(str_split_fixed(input_word, pattern = "",
n = nchar(input_word)))
num_samples = 10000
df_search <- data.frame(rand_word = NA)
# when input_chracters == 9 & num_samples > 100,000 this loop is very slow
# however at input_charcter == 9 % num_samples 10,000 word is not found
# w
for(i in 1:num_samples){
df_search[i, 'rand_word'] <- paste(sample(input_vector, size = nchar(input_word), replace = FALSE),
sep = "",
collapse = ""
)
}
# Filter random words to match on in dictionary
df_search_reduced <- df_search %>%
filter(rand_word %in% df_words$word)
# test if word was found
if (output_word %in% df_search_reduced$rand_word) {
print("Your desired word was found!!!")
} else {
print("No words found")
}
# all unique words
paste(unique(df_search_reduced$rand_word))
